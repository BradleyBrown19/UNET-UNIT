{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from fastai.vision.gan import *\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()/'data'/'horse2zebra'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom DataBunch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.vision.image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleImage(ItemBase):\n",
    "    def __init__(self, img1, img2):\n",
    "        self.img1,self.img2 = img1,img2\n",
    "        self.data = [(-1+2*img1.data),(-1+2*img2.data)]\n",
    "    \n",
    "    def apply_tfms(self, tfms, **kwargs):\n",
    "        self.img1 = self.img1.apply_tfms(tfms, **kwargs)\n",
    "        self.img2 = self.img2.apply_tfms(tfms, **kwargs)\n",
    "        self.data = [-1+2*self.img1.data,-1+2*self.img2.data]\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self)->str: return f'{self.__class__.__name__}'\n",
    "    \n",
    "    def to_one(self): \n",
    "        tensor = 0.5+torch.cat(self.data,2)/2\n",
    "        return im.Image(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleImageList(ImageList):\n",
    "    def __init__(self, items, itemsB=None, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.itemsB = itemsB\n",
    "        self.copy_new.append('itemsB')\n",
    "    \n",
    "    def get(self, i):\n",
    "        img1 = super().get(i)\n",
    "        fn = self.itemsB[random.randint(0, len(self.itemsB)-1)]\n",
    "        return DoubleImage(img1, open_image(fn))\n",
    "    \n",
    "    def reconstruct(self, t:Tensor): return t\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folders(cls, path, folderA, folderB, **kwargs):\n",
    "        itemsB = ImageList.from_folder(path/folderB).items\n",
    "        res = super().from_folder(path/folderA, itemsB=itemsB, **kwargs)\n",
    "        res.path = path\n",
    "        return res\n",
    "    \n",
    "    def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n",
    "        \"Set `tfms` to be applied to the xs of the train and validation set.\"\n",
    "        if not tfms: tfms=(None,None)\n",
    "        assert is_listy(tfms) and len(tfms) == 2, \"Please pass a list of two lists of transforms (train and valid).\"\n",
    "        self.train.transform(tfms[0], **kwargs)\n",
    "        self.valid.transform(tfms[1], **kwargs)\n",
    "        if self.test: self.test.transform(tfms[1], **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(12,6), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i] = DoubleImage((xs[i][0]/2+0.5),(xs[i][1]/2+0.5))\n",
    "            xs[i].to_one().show(ax=ax, **kwargs)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    #UNTESTED\n",
    "    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):\n",
    "        \"\"\"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\n",
    "        `kwargs` are passed to the show method.\"\"\"\n",
    "        figsize = ifnone(figsize, (12,3*len(xs)))\n",
    "        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)\n",
    "        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)\n",
    "        for i,(x,z) in enumerate(zip(xs,zs)):\n",
    "            x.to_one().show(ax=axs[i,0], **kwargs)\n",
    "            z.to_one().show(ax=axs[i,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DoubleImageList.from_folders(path, 'horse', 'zebra').split_by_rand_pct(0.2).label_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.create_from_ll(data, bs=1, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiUnet Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    \"A quasi-UNet block, using `PixelShuffle_ICNR upsampling`.\"\n",
    "    def __init__(self, up_in_c:int, x_in_c:int, hook:Hook, final_div:bool=True, blur:bool=False, leaky:float=None,\n",
    "                 self_attention:bool=False):\n",
    "        super().__init__()\n",
    "        self.hook = hook\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky)\n",
    "        self.bn = batchnorm_2d(x_in_c)\n",
    "        ni = up_in_c//2 + x_in_c\n",
    "        nf = ni if final_div else ni//2\n",
    "        self.conv1 = conv_layer(ni, nf, leaky=leaky)\n",
    "        self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention)\n",
    "        self.relu = relu(leaky=leaky)\n",
    "\n",
    "    def forward(self, up_in:Tensor) -> Tensor:\n",
    "        s = self.hook.stored\n",
    "        up_out = self.shuf(up_in)\n",
    "        ssh = s.shape[-2:]\n",
    "        if ssh != up_out.shape[-2:]:\n",
    "            up_out = F.interpolate(up_out, s.shape[-2:], mode='nearest')\n",
    "        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n",
    "        return self.conv2(self.conv1(cat_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_sfs_idxs(sizes:Sizes) -> List[int]:\n",
    "    \"Get the indexes of the layers where the size of the activation changes.\"\n",
    "    feature_szs = [size[-1] for size in sizes]\n",
    "    sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n",
    "    if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n",
    "    return sfs_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, ni, nf):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.bn = batchnorm_2d(nf)\n",
    "        self.conv = Conv2dBlock(nf, nf, ks=5, stride=1, norm=\"bn\", activation=\"relu\", padding=2)\n",
    "        self.shuf = PixelShuffle_ICNR(ni, nf, blur=False, leaky=None)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, xb, body=None):\n",
    "        up_out = self.shuf(xb)\n",
    "        \n",
    "        if(body is not None):\n",
    "            ssh = body.shape[-2:]\n",
    "            if ssh != up_out.shape[-2:]:\n",
    "                up_out = F.interpolate(up_out, body.shape[-2:], mode='nearest')\n",
    "            up_out = self.relu(up_out+self.bn(body))\n",
    "\n",
    "        xb = self.conv(up_out)\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, ks, stride, norm, activation, padding=1):\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d(padding)\n",
    "        \n",
    "        norm_dim = nf\n",
    "        if norm == 'bn':\n",
    "            self.norm = nn.BatchNorm2d(norm_dim)\n",
    "        elif norm == 'in':\n",
    "            #self.norm = nn.InstanceNorm2d(norm_dim, track_running_stats=True)\n",
    "            self.norm = nn.InstanceNorm2d(norm_dim)\n",
    "        elif norm == 'ln':\n",
    "            self.norm = LayerNorm(norm_dim)\n",
    "        elif norm == 'adain':\n",
    "            self.norm = AdaptiveInstanceNorm2d(norm_dim)\n",
    "        elif norm == 'none':\n",
    "            self.norm = None\n",
    "        \n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "        elif activation == 'lrelu':\n",
    "            self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif activation == 'prelu':\n",
    "            self.activation = nn.PReLU()\n",
    "        elif activation == 'selu':\n",
    "            self.activation = nn.SELU(inplace=True)\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'none':\n",
    "            self.activation = None\n",
    "            \n",
    "        self.conv = nn.Conv2d(ni, nf, ks, stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.pad(x))\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.Tensor(num_features).uniform_())\n",
    "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        # print(x.size())\n",
    "        if x.size(0) == 1:\n",
    "            # These two lines run much faster in pytorch 0.4 than the two lines listed below.\n",
    "            mean = x.view(-1).mean().view(*shape)\n",
    "            std = x.view(-1).std().view(*shape)\n",
    "        else:\n",
    "            mean = x.view(x.size(0), -1).mean(1).view(*shape)\n",
    "            std = x.view(x.size(0), -1).std(1).view(*shape)\n",
    "\n",
    "        x = (x - mean) / (std + self.eps)\n",
    "\n",
    "        if self.affine:\n",
    "            shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            x = x * self.gamma.view(*shape) + self.beta.view(*shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlocks(nn.Module):\n",
    "    def __init__(self, num_blocks, dim, norm='in', activation='relu', padding=1):\n",
    "        super(ResBlocks, self).__init__()\n",
    "        self.model = []\n",
    "        for i in range(num_blocks):\n",
    "            self.model += [ResBlock(dim, norm=norm, activation=activation, padding=padding)]\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim, norm='in', activation='relu', padding=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.model = []\n",
    "        self.model += [Conv2dBlock(dim, dim, 3, 1, norm, activation, padding)]\n",
    "        self.model += [Conv2dBlock(dim, dim, 3, 1, norm, activation, padding)]\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiUnet(nn.Module):\n",
    "    def __init__(self, arch:Callable, pretrained:bool=True, cut=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.relu = relu(leaky=None)\n",
    "        \n",
    "        self.bodyA = create_body(arch, pretrained, cut=-3)\n",
    "        self.bodyB = create_body(arch, pretrained, cut=-3)\n",
    "        \n",
    "        self.sfs_szs = model_sizes(self.bodyA, size=(224,224))\n",
    "        self.sfs_idxs = list(reversed(_get_sfs_idxs(self.sfs_szs)))\n",
    "        self.sfsA = hook_outputs([self.bodyA[i] for i in self.sfs_idxs])\n",
    "        x = dummy_eval(self.bodyA, (224, 224)).detach()\n",
    "        \n",
    "        self.sfsB = hook_outputs([self.bodyB[i] for i in self.sfs_idxs])\n",
    "        x = dummy_eval(self.bodyB, (224, 224)).detach()\n",
    "        \n",
    "        unet_blocksA = []\n",
    "        x = torch.tensor([])\n",
    "        x = x.new_full((1, 512, 7, 7), 0)\n",
    "        up_in_c = []\n",
    "        x_in_c = []\n",
    "        for i,idx in enumerate(self.sfs_idxs):\n",
    "            up_in_c.append(int(x.shape[1]))\n",
    "            x_in_c.append(int(self.sfs_szs[idx][1]))\n",
    "            not_final = i!=len(self.sfs_idxs)-1\n",
    "            block = UnetBlock(int(x.shape[1]), int(self.sfs_szs[idx][1]), self.sfsA[i], final_div=not_final, blur=False, self_attention=False).eval()\n",
    "            x = block(x)\n",
    "        \n",
    "        #DecoderA\n",
    "        self.UpBlockA1 = UpBlock(256, 128)\n",
    "        self.UpBlockA2 = UpBlock(128, 64)\n",
    "        self.UpBlockA3 = UpBlock(64, 64)\n",
    "        self.finalDecoderA = nn.Sequential(PixelShuffle_ICNR(64), conv_layer(64, 3))\n",
    "        self.ResA = ResBlocks(4, 256, 'in', 'relu', padding=1)\n",
    "        \n",
    "        #DecoderB\n",
    "        self.UpBlockB1 = UpBlock(256, 128)\n",
    "        self.UpBlockB2 = UpBlock(128, 64)\n",
    "        self.UpBlockB3 = UpBlock(64, 64)\n",
    "        self.ResB = ResBlocks(4, 256, 'in', 'relu', padding=1)\n",
    "        self.finalDecoderB = nn.Sequential(PixelShuffle_ICNR(64), conv_layer(64, 3))\n",
    "\n",
    "        #Shared Layers\n",
    "        self.sharedEncoderLayer = conv_layer(256, 512, stride=2)\n",
    "        self.middleConv = nn.Sequential(nn.BatchNorm2d(512), nn.ReLU(512), conv_layer(512, 512*2, stride=1), nn.Conv2d(512*2, 512, 3, stride=1))\n",
    "        self.UpShared = UpBlock(512, 256)\n",
    "\n",
    "        #Tan layer\n",
    "        self.tanLayer = nn.Tanh()\n",
    "    \n",
    "    \n",
    "    def EncoderA(self, xb):\n",
    "        result = self.bodyA(xb)\n",
    "        return result\n",
    "    \n",
    "    def EncoderB(self, xb):\n",
    "        result = self.bodyB(xb)\n",
    "        return result\n",
    "    \n",
    "    def sharedEncoder(self, xb):\n",
    "        result = self.sharedEncoderLayer(xb)\n",
    "        return result\n",
    "        \n",
    "    def MiddleConv(self, xb):\n",
    "        result = self.middleConv(xb)\n",
    "        return result\n",
    "    \n",
    "    def sharedDecoder(self, xb):\n",
    "        return self.UpShared(xb, None)\n",
    "    \n",
    "    def DecoderA(self, xb, body):\n",
    "        xb = self.ResA(xb)\n",
    "        xb = self.UpBlockA1(xb, body[0].stored)\n",
    "        xb = self.UpBlockA2(xb, body[1].stored)\n",
    "        xb = self.UpBlockA3(xb, body[2].stored)\n",
    "\n",
    "        return self.finalDecoderA(xb)\n",
    "    \n",
    "    def DecoderB(self, xb, body):\n",
    "        xb = self.ResB(xb)\n",
    "        xb = self.UpBlockB1(xb, body[0].stored)\n",
    "        xb = self.UpBlockB2(xb, body[1].stored)\n",
    "        xb = self.UpBlockB3(xb, body[2].stored)\n",
    "\n",
    "        return self.finalDecoderB(xb)\n",
    "    \n",
    "    def forward(self, a, b, *pred):\n",
    "        \n",
    "        #get initial encodings of both\n",
    "        a,b = self.EncoderA(a), self.EncoderB(b)\n",
    "        \n",
    "        #put both through shared encoder and middle conv\n",
    "        a,b = self.sharedEncoder(a), self.sharedEncoder(b)\n",
    "        a,b = self.middleConv(a), self.middleConv(b)\n",
    "        \n",
    "        #put images through shared decoder\n",
    "        a,b = self.sharedDecoder(a), self.sharedDecoder(b)\n",
    "        \n",
    "        #Get images that are supposed to be\n",
    "        aToA, bToB = self.DecoderA(a, body=self.sfsA),self.DecoderB(b, body=self.sfsB)\n",
    "\n",
    "        #Get switched images\n",
    "        aToB, bToA = self.DecoderB(a, body=self.sfsA), self.DecoderA(b, body=self.sfsB)\n",
    "    \n",
    "        allIm = torch.cat((self.tanLayer(aToA), self.tanLayer(bToB), self.tanLayer(aToB), self.tanLayer(bToA)), 0)\n",
    "        \n",
    "        return allIm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_and_res(ni, nf): return nn.Sequential(res_block(ni), conv_layer(ni, nf, stride=2, bias=True, use_activ=False, leaky=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiUNITDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiUNITDiscriminator, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),\n",
    "            conv_and_res(64, 128),\n",
    "            conv_and_res(128, 256),\n",
    "            conv_and_res(256, 512),\n",
    "            nn.Conv2d(512, 1, 3, stride=1),\n",
    "            Flatten()\n",
    "        )\n",
    "    \n",
    "    def forward(self, not_switched, switched, down=2):\n",
    "\n",
    "        not_switched = self.convs(not_switched)\n",
    "        switched = self.convs(switched)\n",
    "\n",
    "        return (not_switched,switched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class critic_loss(nn.Module):\n",
    "    #a is 0 and b is 1 for predictions\n",
    "    def forward(self, output, garbage):\n",
    "        pred_winter = output[0]\n",
    "        pred_summer = output[1]\n",
    "        targWin = pred_winter.new_zeros(*pred_winter.size())\n",
    "        targSum = pred_summer.new_ones(*pred_summer.size())\n",
    "        result_winter = F.mse_loss(pred_winter, targWin)\n",
    "        result_summer = F.mse_loss(pred_summer, targSum)\n",
    "        return result_winter + result_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_learner = Learner(data, MultiUNITDiscriminator(), loss_func=critic_loss(), wd=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#critic_learner.fit_one_cycle(4, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#critic_learner.save('critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#critic_learner.load('criticV5-h2z-zfirst')\n",
    "critic_learner.load('criticV5-sum2win-wfirst')\n",
    "#critic_learner.load('criticV5-an2la')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gan Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLearner(Learner):\n",
    "    \"A `Learner` suitable for GANs.\"\n",
    "    def __init__(self, data:DataBunch, generator:nn.Module, critic:nn.Module, gen_loss_func:LossFunction,\n",
    "                 crit_loss_func:LossFunction, n_crit=None, n_gen=None, switcher:Callback=None, gen_first:bool=False, switch_eval:bool=True,\n",
    "                 show_img:bool=True, clip:float=None, **learn_kwargs):\n",
    "        print('in GANLearner')\n",
    "        gan = GANModule(generator, critic)\n",
    "        loss_func = GANLoss(gen_loss_func, crit_loss_func, gan)\n",
    "        switcher = ifnone(switcher, partial(FixedGANSwitcher, n_crit=n_crit, n_gen=n_gen))\n",
    "        super().__init__(data, gan, loss_func=loss_func, callback_fns=[switcher], **learn_kwargs)\n",
    "        trainer = GANTrainer(self, clip=clip, switch_eval=switch_eval, show_img=show_img)\n",
    "        self.gan_trainer = trainer\n",
    "        self.callbacks.append(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModule(nn.Module):\n",
    "    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n",
    "    def __init__(self, generator:nn.Module=None, critic:nn.Module=None, gen_mode:bool=True):\n",
    "        super().__init__()\n",
    "        print('in GANModule')\n",
    "        self.gen_mode = gen_mode\n",
    "        if generator: self.generator,self.critic = generator,critic\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return self.generator(*args) if self.gen_mode else self.critic(*args)\n",
    "\n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        \"Put the model in generator mode if `gen_mode`, in critic mode otherwise.\"\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(GANModule):\n",
    "    \"Wrapper around `loss_funcC` (for the critic) and `loss_funcG` (for the generator).\"\n",
    "    def __init__(self, loss_funcG:Callable, loss_funcC:Callable, gan_model:GANModule):\n",
    "        super().__init__()\n",
    "        print('in GANLoss')\n",
    "        self.loss_funcG,self.loss_funcC,self.gan_model = loss_funcG,loss_funcC,gan_model\n",
    "\n",
    "    def generator(self, output, x_a, x_b):\n",
    "        \"Evaluate the `output` with the critic then uses `self.loss_funcG` to combine it with `target`.\"\n",
    "        output = torch.split(output, 2, dim=0)\n",
    "        x_a_recon, x_b_recon = torch.split(output[0], 1, dim=0)\n",
    "        x_ab, x_ba = torch.split(output[1], 1, dim=0)\n",
    "        fake_pred_x_aa, fake_pred_x_bb = self.gan_model.critic(x_a_recon, x_b_recon)\n",
    "        fake_pred_x_ab, fake_pred_x_ba = self.gan_model.critic(x_ab, x_ba)\n",
    "        \n",
    "        cycled_output = self.gan_model.generator(x_ba, x_ab)\n",
    "        cycle_a = cycled_output[3]\n",
    "        cycle_b = cycled_output[2]\n",
    "        return self.loss_funcG(x_a, x_b, x_a_recon, x_b_recon, cycle_a, cycle_b, fake_pred_x_ab, fake_pred_x_ba)\n",
    "\n",
    "    def critic(self, real_pred, b, c):\n",
    "        fake = self.gan_model.generator(b.requires_grad_(False), c.requires_grad_(False)).requires_grad_(True)\n",
    "        fake = torch.split(fake, 2, dim=0)\n",
    "        fake_ns = torch.split(fake[0], 1, dim=0)\n",
    "        fake_s = torch.split(fake[1], 1, dim=0)\n",
    "        fake_pred_aToA, fake_pred_bToB = self.gan_model.critic(fake_ns[0], fake_ns[1])\n",
    "        fake_pred_aToB, fake_pred_bToA = self.gan_model.critic(fake_s[0], fake_s[1])\n",
    "        return self.loss_funcC(real_pred[0], real_pred[1], fake_pred_aToA, fake_pred_bToB, fake_pred_aToB, fake_pred_bToA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer(LearnerCallback):\n",
    "    \"Handles GAN Training.\"\n",
    "    _order=-20\n",
    "    def __init__(self, learn:Learner, switch_eval:bool=False, clip:float=None, beta:float=0.98, gen_first:bool=False,\n",
    "                 show_img:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.switch_eval,self.clip,self.beta,self.gen_first,self.show_img = switch_eval,clip,beta,gen_first,show_img\n",
    "        self.generator,self.critic = self.model.generator,self.model.critic\n",
    "\n",
    "    def _set_trainable(self):\n",
    "        train_model = self.generator if     self.gen_mode else self.critic\n",
    "        loss_model  = self.generator if not self.gen_mode else self.critic\n",
    "        requires_grad(train_model, True)\n",
    "        requires_grad(loss_model, False)\n",
    "        if self.switch_eval:\n",
    "            train_model.train()\n",
    "            loss_model.eval()\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Create the optimizers for the generator and critic if necessary, initialize smootheners.\"\n",
    "        if not getattr(self,'opt_gen',None):\n",
    "            self.opt_gen = self.opt.new([nn.Sequential(*flatten_model(self.generator))])\n",
    "        else: self.opt_gen.lr,self.opt_gen.wd = self.opt.lr,self.opt.wd\n",
    "        if not getattr(self,'opt_critic',None):\n",
    "            self.opt_critic = self.opt.new([nn.Sequential(*flatten_model(self.critic))])\n",
    "        else: self.opt_critic.lr,self.opt_critic.wd = self.opt.lr,self.opt.wd\n",
    "        self.gen_mode = self.gen_first\n",
    "        self.switch(self.gen_mode)\n",
    "        self.closses,self.glosses = [],[]\n",
    "        self.smoothenerG,self.smoothenerC = SmoothenValue(self.beta),SmoothenValue(self.beta)\n",
    "        self.recorder.add_metric_names(['gen_loss', 'disc_loss'])\n",
    "        self.imgs,self.titles = [],[]\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        \"Switch in generator mode for showing results.\"\n",
    "        self.switch(gen_mode=True)\n",
    "\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"Clamp the weights with `self.clip` if it's not None, return the correct input.\"\n",
    "        if self.gen_mode:\n",
    "            self.last_input = last_input\n",
    "            \n",
    "        if self.clip is not None:\n",
    "            for p in self.critic.parameters(): p.data.clamp_(-self.clip, self.clip)\n",
    "        test = {'last_input':last_input,'last_target':last_input}\n",
    "        #print(test)\n",
    "        return test\n",
    "    \n",
    "    def on_backward_begin(self, last_loss, last_output, **kwargs):\n",
    "        \"Record `last_loss` in the proper list.\"\n",
    "        last_loss = last_loss.detach().cpu()\n",
    "        if self.gen_mode:\n",
    "            self.smoothenerG.add_value(last_loss)\n",
    "            self.glosses.append(self.smoothenerG.smooth)\n",
    "            self.last_gen = last_output.detach().cpu()\n",
    "            last_gen_split = torch.split(self.last_gen, 1, 0)\n",
    "            self.last_critic_preds_ns = self.gan_trainer.critic(last_gen_split[0].cuda(), last_gen_split[1].cuda())\n",
    "            self.last_critic_preds_s = self.gan_trainer.critic(last_gen_split[2].cuda(), last_gen_split[3].cuda())\n",
    "        else:\n",
    "            self.smoothenerC.add_value(last_loss)\n",
    "            self.closses.append(self.smoothenerC.smooth)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        \"Put the critic or the generator back to eval if necessary.\"\n",
    "        self.switch(self.gen_mode)\n",
    "\n",
    "    def on_epoch_end(self, pbar, epoch, last_metrics, **kwargs):\n",
    "        \"Put the various losses in the recorder and show a sample image.\"\n",
    "        if not hasattr(self, 'last_gen') or not self.show_img: return\n",
    "        data = self.learn.data\n",
    "        inputBPre = torch.unbind(self.last_input[1], dim=0)\n",
    "        aToA = im.Image(self.last_gen[0]/2+0.5)\n",
    "        bToB = im.Image(self.last_gen[1]/2+0.5)\n",
    "        aToB = im.Image(self.last_gen[2]/2+0.5)\n",
    "        bToA = im.Image(self.last_gen[3]/2+0.5)\n",
    "        self.imgs.append(aToA)\n",
    "        self.imgs.append(aToB)\n",
    "        self.imgs.append(bToB)\n",
    "        self.imgs.append(bToA)\n",
    "        self.titles.append(f'Epoch {epoch}-A to A')\n",
    "        self.titles.append(f'Epoch {epoch}-A to B')\n",
    "        self.titles.append(f'Epoch {epoch}-B to B')\n",
    "        self.titles.append(f'Epoch {epoch}-B to A')\n",
    "        pbar.show_imgs(self.imgs, self.titles)\n",
    "        return add_metrics(last_metrics, [getattr(self.smoothenerG,'smooth',None),getattr(self.smoothenerC,'smooth',None)])\n",
    "\n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        \"Switch the model, if `gen_mode` is provided, in the desired mode.\"\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n",
    "        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_critic.opt\n",
    "        self._set_trainable()\n",
    "        self.model.switch(gen_mode)\n",
    "        self.loss_func.switch(gen_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedGANSwitcher(LearnerCallback):\n",
    "    \"Switcher to do `n_crit` iterations of the critic then `n_gen` iterations of the generator.\"\n",
    "    def __init__(self, learn:Learner, n_crit=5, n_gen=1):\n",
    "        super().__init__(learn)\n",
    "        self.n_crit,self.n_gen = 1,1\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Initiate the iteration counts.\"\n",
    "        self.n_c,self.n_g = 0,0\n",
    "\n",
    "    def on_batch_end(self, iteration, **kwargs):\n",
    "        \"Switch the model if necessary.\"\n",
    "        if self.learn.gan_trainer.gen_mode:\n",
    "            self.n_g += 1\n",
    "            n_iter,n_in,n_out = self.n_gen,self.n_c,self.n_g\n",
    "        else:\n",
    "            self.n_c += 1\n",
    "            n_iter,n_in,n_out = self.n_crit,self.n_g,self.n_c\n",
    "        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n",
    "        if target == n_out:\n",
    "            self.learn.gan_trainer.switch()\n",
    "            self.n_c,self.n_g = 0,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class disc_loss(nn.Module):\n",
    "    #a is 0 and b is 1 for predictions\n",
    "    def forward(self, real_pred_a, real_pred_b, aToA, bToB, aToB, bToA):\n",
    "        loss = 0\n",
    "        #Real Image Predictions\n",
    "        loss += F.mse_loss(real_pred_a, real_pred_a.new_zeros(*real_pred_a.size()))\n",
    "\n",
    "        loss += F.mse_loss(real_pred_b, real_pred_b.new_zeros(*real_pred_b.size()))\n",
    "\n",
    "        #Translated Predictions\n",
    "        loss += F.mse_loss(aToB, aToB.new_zeros(*aToB.size()))\n",
    "\n",
    "        loss += F.mse_loss(bToA, bToA.new_ones(*bToA.size()))\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gen_loss(nn.Module):\n",
    "    \n",
    "    def content_similar(self, input, target):\n",
    "        return F.l1_loss(input, target)*(10)\n",
    "    \n",
    "    def should_look_like_a(self, input_fake_pred):\n",
    "        target = input_fake_pred.new_zeros(*input_fake_pred.size())\n",
    "        return F.mse_loss(input_fake_pred, target)\n",
    "    \n",
    "    def should_look_like_b(self, input_fake_pred):\n",
    "        target = input_fake_pred.new_ones(*input_fake_pred.size())\n",
    "        return F.mse_loss(input_fake_pred, target)\n",
    "    \n",
    "    def forward(self, x_a, x_b, x_a_recon, x_b_recon, x_a_cycled, x_b_cycled, fake_pred_x_ab, fake_pred_x_ba):\n",
    "        loss = 0\n",
    "        x_a, x_b, x_a_recon, x_b_recon = torch.unbind(x_a, dim=0)[0], torch.unbind(x_b, dim=0)[0], torch.unbind(x_a_recon, dim=0)[0], torch.unbind(x_a_recon, dim=0)[0]\n",
    "        \n",
    "        loss += self.should_look_like_a(fake_pred_x_ba)\n",
    "        loss += self.should_look_like_b(fake_pred_x_ab)\n",
    "        \n",
    "        loss += self.content_similar(x_a, x_a_recon)*(0.5)\n",
    "        loss += self.content_similar(x_b, x_b_recon)*(0.5)\n",
    "        \n",
    "        loss += self.content_similar(x_a, x_a_cycled)\n",
    "        loss += self.content_similar(x_b, x_b_cycled)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = MultiUnet(models.resnet34)\n",
    "multiGan = GANLearner(data,\n",
    "                      generator=generator,\n",
    "                      critic=critic_learner.model,\n",
    "                      gen_loss_func=gen_loss(),\n",
    "                      crit_loss_func=disc_loss(), opt_func=partial(optim.Adam, betas=(0.5,0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiGan.fit_one_cycle(100, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGan.load('v5-trial1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show input images\n",
    "rows=2\n",
    "x,y = next(iter(data.train_dl))\n",
    "beforeA = torch.unbind(x[0], dim=0)[0].cpu()\n",
    "beforeA = im.Image(beforeA/2+0.5)\n",
    "beforeB = torch.unbind(x[1], dim=0)[0].cpu()\n",
    "beforeB = im.Image(beforeB/2+0.5)\n",
    "images = [beforeA, beforeB]\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "    images[i].show(ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show results\n",
    "pred = multiGan.gan_trainer.generator(x[0], x[1], True)\n",
    "predAA = pred[0]\n",
    "predBB = pred[1]\n",
    "predAB = pred[2]\n",
    "predBA = pred[3]\n",
    "predAA = im.Image(predAA.detach()/2+0.5)\n",
    "predBB = im.Image(predBB.detach()/2+0.5)\n",
    "predAB = im.Image(predAB.detach()/2+0.5)\n",
    "predBA = im.Image(predBA.detach()/2+0.5)\n",
    "images = [predAA, predAB, predBB, predBA]\n",
    "titles = [\"A to A\", \"A to B\", \"B to B\", \"B to A\"]\n",
    "fig, axs = plt.subplots(2,2,figsize=(8,8))\n",
    "for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "    images[i].show(ax=ax, title=titles[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
