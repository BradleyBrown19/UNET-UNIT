{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp encoder_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from fastai.vision.gan import *\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import pdb\n",
    "\n",
    "from pyfiles.building_blocks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder / Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_sfs_idxs(sizes:Sizes) -> List[int]:\n",
    "    \"Get the indexes of the layers where the size of the activation changes.\"\n",
    "    feature_szs = [size[-1] for size in sizes]\n",
    "    sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n",
    "    if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n",
    "    return sfs_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, arch:Callable, pretrained:bool=True, cut=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.relu = relu(leaky=None)\n",
    "        \n",
    "        self.bodyA = create_body(arch, pretrained, cut=-3)\n",
    "        self.bodyB = create_body(arch, pretrained, cut=-3)\n",
    "        \n",
    "        self.sfs_szs = model_sizes(self.bodyA, size=(224,224))\n",
    "        self.sfs_idxs = list(reversed(_get_sfs_idxs(self.sfs_szs)))\n",
    "        self.sfsA = hook_outputs([self.bodyA[i] for i in self.sfs_idxs])\n",
    "        x = dummy_eval(self.bodyA, (224, 224)).detach()\n",
    "        \n",
    "        self.sfsB = hook_outputs([self.bodyB[i] for i in self.sfs_idxs])\n",
    "        x = dummy_eval(self.bodyB, (224, 224)).detach()\n",
    "        \n",
    "        unet_blocksA = []\n",
    "        x = torch.tensor([])\n",
    "        x = x.new_full((1, 512, 7, 7), 0)\n",
    "        up_in_c = []\n",
    "        x_in_c = []\n",
    "        for i,idx in enumerate(self.sfs_idxs):\n",
    "            up_in_c.append(int(x.shape[1]))\n",
    "            x_in_c.append(int(self.sfs_szs[idx][1]))\n",
    "            not_final = i!=len(self.sfs_idxs)-1\n",
    "            block = UnetBlock(int(x.shape[1]), int(self.sfs_szs[idx][1]), self.sfsA[i], final_div=not_final, blur=False, self_attention=False).eval()\n",
    "            x = block(x)\n",
    "        \n",
    "        #DecoderA\n",
    "        self.UpBlockA1 = UpBlock(256, 128)\n",
    "        self.UpBlockA2 = UpBlock(128, 64)\n",
    "        self.UpBlockA3 = UpBlock(64, 64)\n",
    "        self.finalDecoderA = nn.Sequential(PixelShuffle_ICNR(64), conv_layer(64, 3))\n",
    "        self.ResA = ResBlocks(4, 256, 'in', 'relu', padding=1)\n",
    "        \n",
    "        #DecoderB\n",
    "        self.UpBlockB1 = UpBlock(256, 128)\n",
    "        self.UpBlockB2 = UpBlock(128, 64)\n",
    "        self.UpBlockB3 = UpBlock(64, 64)\n",
    "        self.ResB = ResBlocks(4, 256, 'in', 'relu', padding=1)\n",
    "        self.finalDecoderB = nn.Sequential(PixelShuffle_ICNR(64), conv_layer(64, 3))\n",
    "\n",
    "        #Shared Layers\n",
    "        self.sharedEncoderLayer = conv_layer(256, 512, stride=2)\n",
    "        self.middleConv = nn.Sequential(nn.BatchNorm2d(512), nn.ReLU(512), conv_layer(512, 512*2, stride=1), nn.Conv2d(512*2, 512, 3, stride=1))\n",
    "        self.UpShared = UpBlock(512, 256)\n",
    "\n",
    "        #Tan layer\n",
    "        self.tanLayer = nn.Tanh()\n",
    "    \n",
    "    \n",
    "    def EncoderA(self, xb):\n",
    "        result = self.bodyA(xb)\n",
    "        return result\n",
    "    \n",
    "    def EncoderB(self, xb):\n",
    "        result = self.bodyB(xb)\n",
    "        return result\n",
    "    \n",
    "    def sharedEncoder(self, xb):\n",
    "        result = self.sharedEncoderLayer(xb)\n",
    "        return result\n",
    "        \n",
    "    def MiddleConv(self, xb):\n",
    "        result = self.middleConv(xb)\n",
    "        return result\n",
    "    \n",
    "    def sharedDecoder(self, xb):\n",
    "        return self.UpShared(xb, None)\n",
    "    \n",
    "    def DecoderA(self, xb, body):\n",
    "        xb = self.ResA(xb)\n",
    "        xb = self.UpBlockA1(xb, body[0].stored)\n",
    "        xb = self.UpBlockA2(xb, body[1].stored)\n",
    "        xb = self.UpBlockA3(xb, body[2].stored)\n",
    "\n",
    "        return self.finalDecoderA(xb)\n",
    "    \n",
    "    def DecoderB(self, xb, body):\n",
    "        xb = self.ResB(xb)\n",
    "        xb = self.UpBlockB1(xb, body[0].stored)\n",
    "        xb = self.UpBlockB2(xb, body[1].stored)\n",
    "        xb = self.UpBlockB3(xb, body[2].stored)\n",
    "\n",
    "        return self.finalDecoderB(xb)\n",
    "    \n",
    "    def forward(self, a, b, *pred):\n",
    "        \n",
    "        #get initial encodings of both\n",
    "        a,b = self.EncoderA(a), self.EncoderB(b)\n",
    "        \n",
    "        #put both through shared encoder and middle conv\n",
    "        a,b = self.sharedEncoder(a), self.sharedEncoder(b)\n",
    "        a,b = self.middleConv(a), self.middleConv(b)\n",
    "        \n",
    "        #put images through shared decoder\n",
    "        a,b = self.sharedDecoder(a), self.sharedDecoder(b)\n",
    "        \n",
    "        #Get images that are supposed to be\n",
    "        aToA, bToB = self.DecoderA(a, body=self.sfsA),self.DecoderB(b, body=self.sfsB)\n",
    "\n",
    "        #Get switched images\n",
    "        aToB, bToA = self.DecoderB(a, body=self.sfsA), self.DecoderA(b, body=self.sfsB)\n",
    "    \n",
    "        allIm = torch.cat((self.tanLayer(aToA), self.tanLayer(bToB), self.tanLayer(aToB), self.tanLayer(bToA)), 0)\n",
    "        \n",
    "        return allIm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
